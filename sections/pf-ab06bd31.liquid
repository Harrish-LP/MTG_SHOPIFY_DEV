{% comment %}
This file is auto-generated by PageFly. The content can be overridden when publish page in PageFly. Please do not update this file directly.
If you plan to remove PageFly, please see the guide in our help center first: https://help.pagefly.io/.
{% endcomment %}
<link rel="stylesheet" href="{{ 'pagefly.blog.css' | asset_url }}"><article> <div data-pf-editor-version="legacy" class="sc-bkSTSn eCpwvD __pf __pf_ZmhkKE3p" id="__pf"><div data-pf-type="Body" class="sc-lgjIEp kNIIwQ pf-7_"><div data-pf-type="Layout" class="sc-bHnkpz klJjOQ pf-8_"><div data-section-id="pf-47ae" data-pf-type="Section" class="sc-dBFCZX khzvmY pf-9_"><div style="--cw:1170px" class="sc-gvPcJq dRaLso"><div class="sc-hzhKNl fltMam pf-10_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-11_"><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-12_"><i class="sc-dChVQp hgzReS pf-13_ pfa pfa-book-open-reader" data-pf-type="Icon"></i>Dr&nbsp;Richard Dune</h3><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-14_"><i class="sc-dChVQp hgzReS pf-15_ pfa pfa-calendar-days" data-pf-type="Icon"></i>21-02-2025</h3></div></div></div><div class="sc-hzhKNl fltMam pf-16_ pf-r pf-r-eh" style="--s-xs:8px;--s-sm:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-17_"><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-18_">Why AI in healthcare should be regulated?</h3></div></div></div><div class="sc-hzhKNl fltMam pf-20_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-21_"><p class="sc-eONOlN cfGtgs pf-22_" data-pf-type="Paragraph"><span data-pf-type="Text" class="sc-cHMHbD bwTmDt pf-24_">Image by DC_Studio via Envato Elements</span></p></div></div></div></div></div><div data-section-id="pf-e700" data-pf-type="Section" class="sc-dBFCZX khzvmY pf-25_"><div style="--cw:1170px" class="sc-gvPcJq dRaLso"><div class="sc-hzhKNl fltMam pf-26_ pf-r pf-r-eh" style="--s-xs:8px;--s-sm:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-27_"><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-28_">Exploring the need for strong AI regulation to ensure patient safety, ethical practices, and foster innovation
</h3><p class="sc-bhqpXc fHzOVK pf-30_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-43e3ce5e-834f-4bbd-abf2-d472c8bc4ea2"/><span class="pf-paragraph-content ">Artificial Intelligence (AI) is reshaping health and social care at an unprecedented pace, bringing transformative advancements in predictive analytics, automated diagnostics, and clinical decision support systems. AI promises significant benefits; efficiency, cost savings, and improved patient outcomes. However, as AI continues to infiltrate these sectors, the absence of a structured regulatory framework raises serious concerns about patient safety, bias, and accountability.<br><br>To ensure AI tools serve patients, providers, and health systems ethically and safely, they must undergo the same regulatory rigour as pharmaceuticals and medical devices. <br><br>In this blog, <a href="https://www.mandatorytraining.co.uk/blogs/dr-richard-dune/why-ai-in-healthcare-should-be-regulated" target="_blank"><em><span style="color: rgb(74, 144, 226);">Dr Richard Dune</span></em></a> outlines the necessity for a gold-standard AI regulation framework and explains the key components that must be implemented to create a safe, transparent, and accountable AI ecosystem in healthcare.
<br>
</span></p></div></div></div><div class="sc-hzhKNl fltMam pf-33_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-34_"><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-35_">AI in health and social care - Why regulation is crucial</h3><p class="sc-bhqpXc fHzOVK pf-37_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-29097791-772e-40f8-bde2-873bf00c845c"/><span class="pf-paragraph-content ">The development of AI in healthcare is progressing rapidly, but it remains largely unregulated, which leaves AI-driven tools operating in an uncharted space, often deployed before they are fully scrutinised. Unlike new drugs, medical devices, and treatments that undergo rigorous clinical trials and regulatory assessments, AI tools that influence clinical decisions often lack the same level of oversight. This regulatory gap is a fundamental risk to health and social care systems worldwide. Without appropriate governance, the deployment of unregulated AI could result in unsafe medical decisions, bias, and loss of public trust.<br><br>We must ask ourselves: <em>‘Why do AI systems that directly impact patient care not go through the same rigorous process as pharmaceuticals or medical devices?’</em>
<br><br>While AI advocates argue that regulation may stifle innovation, this is a flawed premise. For AI to truly support diagnoses, suggest treatments, and optimise clinical workflows, it must meet the same standards as other medical innovations. Just as we would not allow an untested drug to be given to patients, we cannot afford to deploy unvalidated AI systems into clinical environments.
<br>
</span></p></div></div></div><div class="sc-hzhKNl fltMam pf-40_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-41_"><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-42_">The risks of unregulated AI in health and social care
</h3><p class="sc-bhqpXc fHzOVK pf-44_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-8339e930-7cb0-42a8-8616-b7839104600c"/><span class="pf-paragraph-content ">AI has the potential to transform healthcare by enhancing patient care, but without the proper regulatory measures in place, it poses significant risks:
</span></p><div class="sc-bzUkDf bKRpwk pf-47_ pf-icon-right" data-scroll-to-top="true" data-open-multiple="false" data-pf-type="Accordion3"><details class="sc-eeFoZL bguFnT pf-48_" data-pf-type="Accordion3.Content.Wrapper"><summary><div class="sc-crvJBB jZphKJ pf-49_ pf-anchor pf-header-item-wrapper" data-header-id="a78b9878-668a-4745-bd99-bafacf5a56ca" data-active="false" data-pf-type="Accordion3.Header"><svg class="pf-accordion-icon pfa-chevron-right pfa-arrow" style="width:auto;fill:currentcolor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><span>Algorithmic bias and health inequality
</span></div></summary><div class="sc-eudKmy ffUBTa pf-51_ pf-accordion-body" data-pf-expandable="true" data-pf-type="Accordion3.Content"><div class="pf-accordion-display-content"><div data-pf-type="Accordion3.Flex.Content" class="sc-flFjkU kahMgJ pf-52_"><div class="sc-hzhKNl fltMam pf-53_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-54_"><p class="sc-bhqpXc fHzOVK pf-55_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-0f29c255-63c7-4a74-8164-424a2f86965d"/><span class="pf-paragraph-content ">AI models are trained on historical data, which may reflect biases in past healthcare decisions. These biases could lead to disparities in care, reinforcing existing inequalities. For example, AI-powered diagnostics trained predominantly on data from white male patients may produce inaccurate results for women or ethnic minorities.<br><br><strong>Regulation solution</strong> - AI regulation must ensure diverse, representative datasets and ongoing monitoring to detect and mitigate bias in AI models, ensuring equitable and accurate healthcare delivery for all patients.
<br>
</span></p></div></div></div></div></div></div></details><details class="sc-eeFoZL bguFnT pf-58_" data-pf-type="Accordion3.Content.Wrapper"><summary><div class="sc-crvJBB jZphKJ pf-59_ pf-anchor pf-header-item-wrapper" data-header-id="6cc69d72-93ae-42a1-9f9f-f750f27632db" data-active="false" data-pf-type="Accordion3.Header"><svg class="pf-accordion-icon pfa-chevron-right pfa-arrow" style="width:auto;fill:currentcolor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><span>Lack of Transparency (Black-box decision-making)
</span></div></summary><div class="sc-eudKmy ffUBTa pf-61_ pf-accordion-body" data-pf-expandable="true" data-pf-type="Accordion3.Content"><div class="pf-accordion-display-content"><div data-pf-type="Accordion3.Flex.Content" class="sc-flFjkU kahMgJ pf-62_"><div class="sc-hzhKNl fltMam pf-63_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-64_"><p class="sc-bhqpXc fHzOVK pf-65_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-b2a15f9f-f750-4276-b2db-408c2ba64236"/><span class="pf-paragraph-content ">A key concern with AI in healthcare is the "black-box" nature of many algorithms. AI systems can often operate without providing clear explanations, making it difficult for clinicians to understand or challenge their recommendations. In a sector where clinical accountability is paramount, this lack of transparency can undermine trust in AI systems.<br><br><strong>Regulation solution</strong> - Regulatory frameworks should require AI developers to implement explainable AI (XAI) systems, allowing clinicians to investigate and challenge decisions before taking action, ensuring a higher level of accountability and trust.
<br>
</span></p></div></div></div></div></div></div></details><details class="sc-eeFoZL bguFnT pf-68_" data-pf-type="Accordion3.Content.Wrapper"><summary><div class="sc-crvJBB jZphKJ pf-69_ pf-anchor pf-header-item-wrapper" data-header-id="eaf5de83-936b-4569-8a94-0162bd972477" data-active="false" data-pf-type="Accordion3.Header"><svg class="pf-accordion-icon pfa-chevron-right pfa-arrow" style="width:auto;fill:currentcolor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><span>Regulatory gaps and ethical concerns
</span></div></summary><div class="sc-eudKmy ffUBTa pf-71_ pf-accordion-body" data-pf-expandable="true" data-pf-type="Accordion3.Content"><div class="pf-accordion-display-content"><div data-pf-type="Accordion3.Flex.Content" class="sc-flFjkU kahMgJ pf-72_"><div class="sc-hzhKNl fltMam pf-73_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-74_"><p class="sc-bhqpXc fHzOVK pf-75_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-55698a94-0162-4d97-a477-c4c0b40502f1"/><span class="pf-paragraph-content ">Currently, many policymakers and health leaders lack the necessary expertise to assess AI technology properly. This absence of clear governance allows AI adoption to be driven primarily by tech companies and commercial interests rather than patient safety and clinical needs.<br><br><strong>Regulation solution</strong> - Comprehensive AI regulation should include independent validation of AI tools before deployment in clinical settings, clear accountability frameworks for AI-driven decisions, and ethical guidelines prioritising patient autonomy and consent in AI-driven care.
<br>
</span></p></div></div></div></div></div></div></details><details class="sc-eeFoZL bguFnT pf-78_" data-pf-type="Accordion3.Content.Wrapper"><summary><div class="sc-crvJBB jZphKJ pf-79_ pf-anchor pf-header-item-wrapper" data-header-id="83f37972-8b37-492d-a68b-9d9cc9a8299c" data-active="false" data-pf-type="Accordion3.Header"><svg class="pf-accordion-icon pfa-chevron-right pfa-arrow" style="width:auto;fill:currentcolor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><span>Workforce readiness and training
</span></div></summary><div class="sc-eudKmy ffUBTa pf-81_ pf-accordion-body" data-pf-expandable="true" data-pf-type="Accordion3.Content"><div class="pf-accordion-display-content"><div data-pf-type="Accordion3.Flex.Content" class="sc-flFjkU kahMgJ pf-82_"><div class="sc-hzhKNl fltMam pf-83_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-84_"><p class="sc-bhqpXc fHzOVK pf-85_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-792da68b-9d9c-49a8-a99c-09a6870cc6eb"/><span class="pf-paragraph-content ">AI should augment human expertise, not replace it. However, healthcare professionals must be adequately trained to work alongside AI tools. If AI adoption outpaces workforce development, there is a risk of overreliance on automated decisions without the necessary human oversight.<br>
<strong><br>Regulation solution</strong> - AI regulation should require structured AI competency training for clinicians and healthcare professionals, ensuring responsible and effective use of AI in clinical settings.
</span></p></div></div></div></div></div></div></details></div></div></div></div><div class="sc-hzhKNl fltMam pf-88_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-89_"><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-90_">Global disunity in AI governance - The need for a unified approach
</h3><p class="sc-bhqpXc fHzOVK pf-92_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-e3d00d80-df15-4a49-851a-50352a1fa86e"/><span class="pf-paragraph-content ">Despite AI's undeniable potential, global regulation remains fragmented. Recent discussions at the Paris AI Summit (February 2025) and the Munich Security Conference (15 February 2025) highlighted the division between AI policy approaches in different regions. The European Union and China push for stricter controls, while the United States and the United Kingdom advocate for a more flexible, innovation-driven approach. This divide creates risks, as AI developers could deploy systems in less-regulated regions, exacerbating disparities in patient safety and care quality.
<br><br>We must ask: <em>‘Would we accept a healthcare system where drugs and treatments were regulated in some countries but not in others?’</em><br><br>To ensure patient safety globally, we must move towards multilateral cooperation. The UK, US, EU, and other major AI stakeholders must align on baseline safety and ethical standards, creating a unified framework that protects patients while promoting innovation.
</span></p></div></div></div><div class="sc-hzhKNl fltMam pf-95_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-96_"><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-97_">Bridging the gap - A call for a gold-standard AI regulation framework
</h3><p class="sc-bhqpXc fHzOVK pf-99_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-4fdfa20b-4647-47b3-8d7a-665ea0797943"/><span class="pf-paragraph-content ">To ensure AI serves health systems safely and ethically, we must develop a comprehensive regulatory framework prioritising patient safety, transparency, accountability, and global cooperation. Here’s how a gold-standard regulation framework can be achieved:
</span></p><div class="sc-bzUkDf bKRpwk pf-102_ pf-icon-right" data-scroll-to-top="true" data-open-multiple="false" data-pf-type="Accordion3"><details class="sc-eeFoZL bguFnT pf-103_" data-pf-type="Accordion3.Content.Wrapper"><summary><div class="sc-crvJBB jZphKJ pf-104_ pf-anchor pf-header-item-wrapper" data-header-id="64402f73-7401-4655-ae25-018ec22c4d97" data-active="false" data-pf-type="Accordion3.Header"><svg class="pf-accordion-icon pfa-chevron-right pfa-arrow" style="width:auto;fill:currentcolor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><span>AI clinical trials and regulatory oversight
</span></div></summary><div class="sc-eudKmy ffUBTa pf-106_ pf-accordion-body" data-pf-expandable="true" data-pf-type="Accordion3.Content"><div class="pf-accordion-display-content"><div data-pf-type="Accordion3.Flex.Content" class="sc-flFjkU kahMgJ pf-107_"><div class="sc-hzhKNl fltMam pf-108_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-109_"><p class="sc-bhqpXc fHzOVK pf-110_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-a6556e25-018e-422c-8d97-81f376640f49"/><span class="pf-paragraph-content ">AI systems influencing clinical decisions should undergo the same rigorous validation processes as medicines and medical devices. This includes:
</span></p><ul style="--pf-line-spacing-xs:10px;--pf-line-spacing-sm:10px;--pf-line-spacing-md:10px;--pf-line-spacing-lg:10px;--pf-text-indent-xs:0px;--pf-text-indent-sm:0px;--pf-text-indent-md:0px;--pf-text-indent-lg:0px" data-pf-type="List2" class="sc-btwLGw cuLvxI pf-113_"><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-114_"><strong>Pre-market validation</strong> - AI systems must be tested through controlled clinical trials to prove their safety, efficacy, and cost-effectiveness, ensuring they meet the necessary clinical standards before deployment.
</li><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-116_"><strong>MHRA &amp; NICE oversight</strong> - AI-driven diagnostic tools and treatment recommendations should undergo scrutiny from regulatory bodies like the Medicines and Healthcare Products Regulatory Agency (MHRA) and the National Institute for Health and Care Excellence (NICE) to ensure they meet clinical efficacy and cost-effectiveness standards.
</li><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-118_"><strong>Post-market surveillance</strong> - AI tools must be subject to continuous monitoring post-deployment to ensure that their real-world performance matches pre-market testing and remains effective and safe throughout their use.
</li></ul></div></div></div></div></div></div></details><details class="sc-eeFoZL bguFnT pf-120_" data-pf-type="Accordion3.Content.Wrapper"><summary><div class="sc-crvJBB jZphKJ pf-121_ pf-anchor pf-header-item-wrapper" data-header-id="0565fb5a-a060-47bf-b44f-272b76fe284b" data-active="false" data-pf-type="Accordion3.Header"><svg class="pf-accordion-icon pfa-chevron-right pfa-arrow" style="width:auto;fill:currentcolor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><span>Algorithmic transparency and accountability
</span></div></summary><div class="sc-eudKmy ffUBTa pf-123_ pf-accordion-body" data-pf-expandable="true" data-pf-type="Accordion3.Content"><div class="pf-accordion-display-content"><div data-pf-type="Accordion3.Flex.Content" class="sc-flFjkU kahMgJ pf-124_"><div class="sc-hzhKNl fltMam pf-125_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-126_"><p class="sc-bhqpXc fHzOVK pf-127_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-b7bfb44f-272b-46fe-a84b-843c87ecba87"/><span class="pf-paragraph-content ">For AI to be trusted and used effectively in healthcare, developers must ensure transparency in how AI systems make decisions:
</span></p><ul style="--pf-line-spacing-xs:10px;--pf-line-spacing-sm:10px;--pf-line-spacing-md:10px;--pf-line-spacing-lg:10px;--pf-text-indent-xs:0px;--pf-text-indent-sm:0px;--pf-text-indent-md:0px;--pf-text-indent-lg:0px" data-pf-type="List2" class="sc-btwLGw cuLvxI pf-130_"><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-131_"><strong>Explainability requirements</strong> - AI systems must provide clinicians with clear, interpretable outputs to facilitate informed decision-making.
</li><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-133_"><strong>Bias detection and mitigation</strong> - Regular audits must be conducted to detect and correct any biases in AI models, ensuring they provide accurate outcomes for all patient demographics.
</li><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-135_"><strong>Clear accountability structures</strong> - Responsibility for AI-driven errors must be clearly defined, whether at the developer, provider, or clinician level.
</li></ul></div></div></div></div></div></div></details><details class="sc-eeFoZL bguFnT pf-137_" data-pf-type="Accordion3.Content.Wrapper"><summary><div class="sc-crvJBB jZphKJ pf-138_ pf-anchor pf-header-item-wrapper" data-header-id="2b80ab61-f1ab-4c55-9edf-5c248c0f2afd" data-active="false" data-pf-type="Accordion3.Header"><svg class="pf-accordion-icon pfa-chevron-right pfa-arrow" style="width:auto;fill:currentcolor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><span>Workforce training and AI competency standards
</span></div></summary><div class="sc-eudKmy ffUBTa pf-140_ pf-accordion-body" data-pf-expandable="true" data-pf-type="Accordion3.Content"><div class="pf-accordion-display-content"><div data-pf-type="Accordion3.Flex.Content" class="sc-flFjkU kahMgJ pf-141_"><div class="sc-hzhKNl fltMam pf-142_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-143_"><p class="sc-bhqpXc fHzOVK pf-144_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-0c555edf-5c24-4c0f-aafd-1d933f237e4e"/><span class="pf-paragraph-content ">Healthcare professionals must be equipped to use AI responsibly:
</span></p><ul style="--pf-line-spacing-xs:10px;--pf-line-spacing-sm:10px;--pf-line-spacing-md:10px;--pf-line-spacing-lg:10px;--pf-text-indent-xs:0px;--pf-text-indent-sm:0px;--pf-text-indent-md:0px;--pf-text-indent-lg:0px" data-pf-type="List2" class="sc-btwLGw cuLvxI pf-147_"><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-148_"><strong>AI literacy for healthcare professionals</strong> - Comprehensive training in AI best practices, ethical considerations, and risk mitigation should be standard for all clinicians.
</li><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-150_"><strong>Clinical AI certification</strong> - AI-driven decision-support tools must undergo certification processes, similar to medical equipment approvals, to ensure they meet safety and efficacy standards before being used in clinical settings.
</li></ul></div></div></div></div></div></div></details><details class="sc-eeFoZL bguFnT pf-152_" data-pf-type="Accordion3.Content.Wrapper"><summary><div class="sc-crvJBB jZphKJ pf-153_ pf-anchor pf-header-item-wrapper" data-header-id="9d022fa8-c799-4a06-b690-3d19ed82fb19" data-active="false" data-pf-type="Accordion3.Header"><svg class="pf-accordion-icon pfa-chevron-right pfa-arrow" style="width:auto;fill:currentcolor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><span>International AI regulation and global standards
</span></div></summary><div class="sc-eudKmy ffUBTa pf-155_ pf-accordion-body" data-pf-expandable="true" data-pf-type="Accordion3.Content"><div class="pf-accordion-display-content"><div data-pf-type="Accordion3.Flex.Content" class="sc-flFjkU kahMgJ pf-156_"><div class="sc-hzhKNl fltMam pf-157_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-158_"><p class="sc-bhqpXc fHzOVK pf-159_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-2a067690-3d19-4d82-bb19-d90ee7d3a884"/><span class="pf-paragraph-content ">To prevent discrepancies in AI deployment across borders, a coordinated global effort is necessary:
</span></p><ul style="--pf-line-spacing-xs:10px;--pf-line-spacing-sm:10px;--pf-line-spacing-md:10px;--pf-line-spacing-lg:10px;--pf-text-indent-xs:0px;--pf-text-indent-sm:0px;--pf-text-indent-md:0px;--pf-text-indent-lg:0px" data-pf-type="List2" class="sc-btwLGw cuLvxI pf-162_"><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-163_"><strong>Multilateral cooperation</strong> - Major AI players, such as the UK, US, EU, and China, must align on baseline safety and ethical standards to prevent fragmented regulation and ensure patient safety worldwide.
</li><li data-pf-type="List2.Item2" class="sc-gFmZvT eCWkjm pf-165_"><strong>Public-private collaboration</strong> - Governments, healthcare providers, and tech companies must collaborate to create and implement AI regulatory frameworks that balance innovation and safety.
</li></ul></div></div></div></div></div></div></details></div></div></div></div><div class="sc-hzhKNl fltMam pf-167_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-168_"><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-169_">Conclusion - AI Regulation is a necessity, not an obstacle
</h3><p class="sc-bhqpXc fHzOVK pf-171_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-e40a0579-2d30-4509-9f9f-dc96582aa865"/><span class="pf-paragraph-content ">AI has immense potential to improve healthcare, but its deployment cannot be left to the market alone. Without regulation, AI poses significant risks, including exacerbating health inequalities, reducing transparency in clinical decision-making, and introducing patient safety risks.<br><br>Just as no new drug is introduced to the market without rigorous trials and regulatory approval, no AI system impacting clinical care should be used without equivalent safeguards. The UK’s innovation-first approach must be balanced with structured oversight to ensure AI benefits patients, not just tech companies.
<br><br>Now is the time to act before we face the irreversible consequences of unregulated AI, which could lead to misdiagnoses, biased treatments, and patient safety failures that may take decades to resolve.
</span></p></div></div></div><div class="sc-hzhKNl fltMam pf-174_ pf-r pf-r-eh" style="--s-xs:15px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:12;--c-md:12;--c-lg:12"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-175_"><h3 data-pf-type="Heading2" class="sc-cXPBhi kkWDYP pf-176_">Call to action - Driving compliance and innovation with ComplyPlus™
</h3><p class="sc-bhqpXc fHzOVK pf-178_" data-pf-type="Paragraph4"><input type="checkbox" id="compact-e5c40b6b-a37f-44c1-81ee-e496fe4371bb"/><span class="pf-paragraph-content ">As the development and integration of AI in healthcare continue to evolve, the need for robust regulatory frameworks becomes increasingly clear. The development of ComplyPlus™ has been driven by a commitment to ensuring healthcare providers meet the highest compliance standards while embracing innovation.<br><br>
</span></p><a data-to-section="pf-5c00" data-offset="{&quot;all&quot;:50,&quot;laptop&quot;:50,&quot;tablet&quot;:50,&quot;mobile&quot;:50}" href="#" data-pf-type="Button2" class="sc-iLLNPL jkrxGm pf-181_">ComplyPlus™ empowers organisations to manage regulatory compliance, workforce training, and AI competency, ensuring they can safely integrate AI solutions into their practices. <em><span style="color: rgb(74, 144, 226);">Fill in this form</span></em> or contact us at +44 24 7610 0090 to learn how ComplyPlus™ can help your organisation navigate the complex regulation and compliance landscape.</a></div></div></div></div></div><div data-section-id="pf-9872" data-pf-type="Section" class="sc-dBFCZX khzvmY pf-183_ pf-color-scheme-1"><div style="--cw:1170px" class="sc-gvPcJq dRaLso"><div class="sc-hzhKNl fltMam pf-184_ pf-r pf-c-cm" style="--s-xs:0px;--s-sm:15px;--s-lg:0px" data-pf-type="Row"><div class="pf-c" style="--c-xs:12;--c-sm:6;--c-md:6;--c-lg:6"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-185_"><h3 data-pf-type="Heading" class="sc-fUklNj thmnJ pf-186_ pf-heading-1-h3 _Y6RW61"><span data-pf-type="Text" class="sc-cHMHbD bwTmDt pf-188_">About the author
</span></h3><h3 data-pf-type="Heading" class="sc-fUklNj thmnJ pf-189_ pf-heading-1-h3 _Y6RW61"><span data-pf-type="Text" class="sc-cHMHbD bwTmDt pf-191_">Dr Richard Dune
</span></h3><p class="sc-eONOlN cfGtgs pf-192_ pf-text-1" data-pf-type="Paragraph"><span data-pf-type="Text" class="sc-cHMHbD bwTmDt pf-194_">With over 25 years of experience, <a href="https://www.mandatorytraining.co.uk/pages/dr-richard-dune-blog" target="_blank"><em><span style="color: rgb(74, 144, 226);">Dr Richard Dune</span></em></a> has a rich background in the NHS, the private sector, academia, and research settings. His forte lies in clinical R&amp;D, advancing healthcare tech, workforce development, and governance. His leadership ensures that regulatory compliance and innovation align seamlessly.
</span></p></div></div><div class="pf-c" style="--c-xs:12;--c-sm:6;--c-md:6;--c-lg:6"><div data-pf-type="Column" class="sc-fatbYi lnCFtg pf-195_"><img src="https://cdn.shopify.com/s/files/1/0937/2788/t/33/assets/whatsapp-image-20221214-at-080949-1675837553742.png?v=1675837558" srcSet="https://cdn.shopify.com/s/files/1/0937/2788/t/33/assets/whatsapp-image-20221214-at-080949-1675837553742.png?v=1675837558 1536w" width="1024" height="1024" alt="Taking a closer look at Steve Jobs's "Secrets of Life" interview - The Mandatory Training Group UK -" title="Taking a closer look at Steve Jobs's "Secrets of Life" interview - The Mandatory Training Group UK -" data-pf-type="Image3" class="sc-gtJxSR jkHSry pf-196_ pf-image-1"/></div></div></div></div></div><div data-section-id="pf-ed50" data-pf-type="GlobalSection" id="53759150-1f9a-4b11-84c0-258c575fc26f" class="pf-211_" store="[object Object]">{% capture content %}{% include 'pf-53759150' %}{% endcapture %}
            {% if content contains "Liquid error" %}
            {% else %}
            {% render 'pf-53759150' %}
            {% endif %}</div></div></div></div><script>
    !function(){
      window.__pagefly_page_setting__ = {"pageTitle":"Why AI in healthcare should be regulated?","pageType":"blog","pageId":"ab06bd31-f735-4a8a-948e-763919629a04","lazyLoad":false,"forceByPassGoogleLightHouse":false,"imageLazyLoad":false,"nativeImageLazyLoad":true,"useThemeJQ":false,"sectionRootType":"Section","trackingIDs":[]};
      window.__pagefly_setting__&&(window.__pagefly_setting2__=window.__pagefly_setting__),window.__pagefly_setting__={"baseURL":"https://apps.pagefly.io","analyticsURL":"https://analytics.pagefly.io","isBackend":false,"cdnURL":"https://cdn.pagefly.io","pageflyVersion":"4.23.10.1","shopDomain":"regal-training.myshopify.com","elementData":{},"shopifyProxyPath":"/apps/pagefly"},window.__pagefly_setting2__&&(window.__pagefly_setting__=function _(d,b){let c={...d||{}};for(let a of Object.keys(b))b[a]instanceof Object&&(Array.isArray(b[a])&&c[a]?Object.assign(b[a],[...b[a],...c[a]]):Object.assign(b[a],_(c[a],b[a])));return Object.assign(c||{},b),c}(__pagefly_setting2__,__pagefly_setting__),delete window.__pagefly_setting2__),window.__pagefly_setting__.moneyFormat={{shop.money_format|json}}}();
    </script> </article>
{% schema %}
{
  "name": "PageFly Page ab06bd31",
  "settings": [
    {
      "type": "paragraph",
      "content": "For full configuration, [visit PageFly Editor](https://regal-training.myshopify.com/admin/apps/pagefly/editor?id=ab06bd31-f735-4a8a-948e-763919629a04&type=blog)."
    }
  ],
  "blocks": [
    {
      "type": "@app"
    }
  ]
}
{% endschema %}